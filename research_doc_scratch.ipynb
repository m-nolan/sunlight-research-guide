{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = './4. Research Guide.xlsx'\n",
    "research_df = pd.read_excel(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_obj = research_df.sort_values('Resource').iterrows()\n",
    "row = next(iter_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category                                                               NaN\n",
       "Resource                                                             4chan\n",
       "Use This Resource To:    (you can scrape using 4plebs)\\nThis is an Engl...\n",
       "Description                                                            NaN\n",
       "Link                                                                   NaN\n",
       "Search Terms                                                           NaN\n",
       "Date Completed                                                         NaN\n",
       "Research Notes                                                         NaN\n",
       "Name: 115, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('research-guide.txt','w') as f:\n",
    "    for o_idx, row in research_df.sort_values('Resource').iterrows():        \n",
    "        print(f'## {row.Resource}\\n',file=f)\n",
    "        print(f'*{row.Category}*\\n',file=f)\n",
    "        if isinstance(row.Link,str):\n",
    "            link_list = [r for r in row.Link.split('\\n') if len(r) > 0]\n",
    "            print(f\"Links:\\n\",file=f)\n",
    "            for link in link_list:\n",
    "                print(f'- {link}',file=f)\n",
    "            print('\\n',file=f)\n",
    "        print(f'Description: {row.Description}\\n',file=f)\n",
    "        print(f'Uses:\\n{row[\"Use This Resource To:\"]}',file=f)\n",
    "        print('\\n',file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       https://tloxp.tlo.com/login\n",
       "1      https://www.signalhire.com/login?utm_block=1\n",
       "2              Will vary depending on jurisdiction.\n",
       "3              Will vary depending on jurisdiction.\n",
       "4              Will vary depending on jurisdiction.\n",
       "                           ...                     \n",
       "146                                             NaN\n",
       "147                                             NaN\n",
       "148                                             NaN\n",
       "149                                             NaN\n",
       "150                                             NaN\n",
       "Name: Link, Length: 151, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_df['Link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Associated People\n",
      "- Background and Family\n",
      "- Civil Litigation and Criminal Cases\n",
      "- Educational History\n",
      "- Nonprofits\n",
      "- Personal Finances\n",
      "- Political History\n",
      "- Professional History\n",
      "- Social Media and Other Internet Sources\n"
     ]
    }
   ],
   "source": [
    "# Making the ToC: organization of the alphabetical list below it.\n",
    "categories = [re.findall('(.+)\\n\\n -',s) for s in research_df['Use This Resource To:'] if isinstance(s,str)]\n",
    "for p in np.unique([c for cc in categories for c in cc]):\n",
    "    print(f'- {p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at that: lots of misspellings, different labels for the same thing, overlap between categories. Looks like we need to clean up the spreadsheet before moving forward.\n",
    "# \n",
    "# That said, it should be straightforward to make a list of these categories and print all the resources that contain them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_rep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
